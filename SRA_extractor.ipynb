{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afaf7030-b5d1-43d8-b8f4-70f61014ddd7",
   "metadata": {},
   "source": [
    "# SRA Extractor\n",
    "\n",
    "Input: Excel file with Bioprojects IDs and their Description\n",
    "Output : Excel file with SRA IDs and BioSample IDs for each Bioproject ID extracted from NCBI.\n",
    "\n",
    "This script also filter out Bioprojects based on their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab4313-73c3-430d-93ae-9ee1b5d75458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import pysradb\n",
    "from Bio import Entrez\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b263a8-1aed-4efd-a6f7-e3b6f541389b",
   "metadata": {},
   "source": [
    "Pre-processing Data as per requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e144409-b5ac-4260-8a18-3ae675608b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the TSV file\n",
    "df = pd.read_csv('BioProjects.tsv', delimiter='\\t')\n",
    "print(\"Total Samples = \" + str(len(df.index)))\n",
    "\n",
    "# Filter for descriptions with \"metatranscriptome\"\n",
    "df = df[df['description'].str.contains('metatranscriptome', case=False)]\n",
    "\n",
    "# Remove duplicate descriptions\n",
    "df = df.drop_duplicates(subset='description', keep='first')\n",
    "\n",
    "# Remove duplicate accession numbers, keeping the first occurrence\n",
    "df = df.drop_duplicates(subset='accession', keep='first')\n",
    "\n",
    "print(\"Total samples after removing duplicates = \" + str(len(df.index)))\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79091eb3-0c63-4bef-a6bf-68b39f207497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after = df[df['description'].str.contains('after', case=False, na=False)]\n",
    "df_after.sample()\n",
    "print(\"Total Samples including different timepoints = \" + str(len(df_after.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc09fbf-df20-4005-a445-6536126c9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the df.description into two comlumns, split by \"after\"\n",
    "df_after[['description', 'Time_point']] = df_after.description.str.split(\"after\", expand = True)\n",
    "df_after.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a60ba-3d97-49af-b48b-46e7c8dfe33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing multiple timepoints\n",
    "df_unique_time = df_after.drop_duplicates(subset='description', keep='first')\n",
    "print(len(df_unique_time.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baee293-1a2c-4b7b-a683-f4a686fc3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining both columns together\n",
    "df_unique_time[\"whole_description\"] = df_unique_time[\"description\"] + \" after \" + df_unique_time[\"Time_point\"]\n",
    "df_joined_col = df_unique_time.drop([\"description\", \"Time_point\"], axis=1)\n",
    "df_joined_col.sample()\n",
    "df_joined_col.rename(columns={'whole_description': 'description'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcb755-de27-476c-982a-c031146c3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list for indices to Drop\n",
    "\n",
    "indices_to_drop = []\n",
    "for i, row in df.iterrows():\n",
    "        if 'after' in row['description']:\n",
    "            indices_to_drop.append(i)\n",
    "df_no_after=df.drop(indices_to_drop)\n",
    "\n",
    "print(len(df_no_after.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c240eb-3893-4b9f-9cae-2698c959c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both dfs.\n",
    "\n",
    "frame= [df_no_after, df_joined_col]\n",
    "new_df = pd.concat(frame)\n",
    "print(len(new_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f41468-5911-45ca-a657-25d10f9f10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a second list of indices to drop.\n",
    "indices_to_drop_second = []\n",
    "for i, row in df.iterrows():\n",
    "        if 'Tara Oceans' in row['description']:\n",
    "            indices_to_drop_second.append(i)\n",
    "new_df=new_df.drop(indices_to_drop_second)\n",
    "print(len(new_df.index))\n",
    "print(new_df[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af26fd-9860-4667-bd35-c9ddc0e5f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the filtered Bioprojects into an excel file\n",
    "new_df.to_excel(\"ena_project_filtered.xlsx\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f10dbf-6b2b-4f27-932e-583efb87ebb4",
   "metadata": {},
   "source": [
    "Getting SRA available for each Project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d0cc4-e3a9-4dff-8837-892244d1989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accession_numbers = new_df['accession'].tolist()\n",
    "\n",
    "data = []\n",
    "success_count = 0\n",
    "for accession_number in tqdm(accession_numbers, desc=f'Processing accession numbers'):\n",
    "    try:\n",
    "        # Define BioProject ID of interest\n",
    "        bioproject_id = \"PRJNA550452\"\n",
    "        # Create connection to SRA database\n",
    "        sradb = pysradb.SRAweb()\n",
    "        # Retrieve metadata associated with BioProject ID\n",
    "        metadata = sradb.sra_metadata(accession_number)\n",
    "        if metadata is not None:\n",
    "            # Extract list of SRA IDs\n",
    "            sra_ids = metadata['run_accession'].tolist()\n",
    "            data.append([accession_number, sra_ids])  # Append [accession_number, sra_ids] to data list\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "sra_df = pd.DataFrame(data, columns=['accession', 'sra_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c487e45c-ad47-4982-914d-f3effc238fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting fetched SRAs into an excel file\n",
    "sra_df.to_excel(\"SRA_ids.xlsx\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897cd9d-1f6a-45f3-94bd-6e525d88da93",
   "metadata": {},
   "source": [
    "Getting BioSample IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25064-0fd5-42b3-bc29-b8725e1ca964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_test = pd.read_excel('SRA_ids.xlsx')\n",
    "\n",
    "biosample_ids = []\n",
    "for bioproject_id in tqdm(sra_df['accession'], desc='Processing BioProject IDs for BioSamples'):\n",
    "    try:\n",
    "        url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=bioproject&db=biosample&id={bioproject_id}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"xml\")\n",
    "        link = soup.find(\"LinkSetDb\", dbTo=\"biosample\")\n",
    "        biosample_id = link.find(\"Id\").text if link is not None else \"\"\n",
    "    except Exception as e:\n",
    "        biosample_id = \"\"\n",
    "    biosample_ids.append(biosample_id)\n",
    "\n",
    "sra_test['BioSample Id'] = biosample_ids\n",
    "sra_test.to_csv('sra_metadata_with_biosample.csv', index=False)  # replace with the path where you want to save the updated metadata file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a280099-8d06-41c0-a647-7a7dd160f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting Biosamples into excel file.\n",
    "sra_test.to_excel(\"SRA_Biosample_tes1.xlsx\", index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
